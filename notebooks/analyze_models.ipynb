{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"analyze_models.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/models/blob/master/official/colab/fine_tuning_bert.ipynb","timestamp":1606696483960}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z69h4UZ2l9sT","executionInfo":{"status":"ok","timestamp":1619162231707,"user_tz":420,"elapsed":398,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"fb54c07a-7350-4b2b-c59c-cb72031e97b0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/News_Classification"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1EgYdJ-mvNhzcz5FT18MSZz5pO5bmDV9d/News_Classification\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2B867h8ClrAJ","executionInfo":{"status":"ok","timestamp":1619162237149,"user_tz":420,"elapsed":5822,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"7406f2f8-a154-4471-99d3-ef194eede496"},"source":["!pip install torch\n","!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FkdYUTcplvEz","executionInfo":{"status":"ok","timestamp":1619162247551,"user_tz":420,"elapsed":16209,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["import os\n","import time\n","import json\n","import logging\n","from dataclasses import dataclass\n","from tqdm import tqdm\n","from functools import partial\n","tqdm = partial(tqdm, position=0, leave=True)\n","\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from transformers import pipeline\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdN0Nt9oxeCY","executionInfo":{"status":"ok","timestamp":1619162247552,"user_tz":420,"elapsed":16205,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["checkpoint_path = os.path.join(os.getcwd(), \"checkpoints\")\n","dataset_path = os.path.join(os.getcwd(), 'dataset')\n","test_data_path = os.path.join(dataset_path, 'processed_test.json')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"IOyT4TR26lBN","executionInfo":{"status":"ok","timestamp":1619162247553,"user_tz":420,"elapsed":16200,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")\n","else:\n","    device = torch.device(\"cpu\")\n","\n","batch_size = 8\n","max_token_len = 1024\n","temperature = 0.1\n","checkpoint_name_list = os.listdir(checkpoint_path)[7: 9]  # choose 3 to 4 models"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9FO86ffZufLm","executionInfo":{"status":"ok","timestamp":1619162247554,"user_tz":420,"elapsed":16196,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"dd5638a6-417f-4f72-b7a9-fd3460ddccec"},"source":["checkpoint_name_list"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['checkpoint_3249.bin', 'checkpoint_3610.bin']"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"xQvlUpxQyLp3","executionInfo":{"status":"ok","timestamp":1619162317816,"user_tz":420,"elapsed":86440,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["classifier = pipeline(\n","    'zero-shot-classification',\n","    tokenizer='facebook/bart-large-mnli',\n","    model='facebook/bart-large-mnli',\n","    device=device.index,\n","    framework='pt',\n",")"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8w6-mS2mGIHO","executionInfo":{"status":"ok","timestamp":1619162317818,"user_tz":420,"elapsed":86426,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"6706ebab-4194-4cc8-a381-473623fa688d"},"source":["# Reference from: https://github.com/yinwenpeng/BenchmarkingZeroShot/blob/master/src/train_yahoo.py\n","hypothesis_template = \"This text {}.\"\n","\n","choice_to_hypothesis = {\n","    \"Containment and Closure Policies\": [\n","        'is related with containment and closure policy from governments in the pandemic',\n","    ],\n","    \"Economic Policies\": [\n","        'is related with economic policy from governments in the pandemic', \n","    ],\n","    \"Health System Policies\": [\n","        'is related with health system policy from governments in the pandemic',\n","    ],\n","    \"Miscellaneous Policies\": [\n","        'is related with miscellaneous policy from governments in the pandemic', \n","    ]\n","}\n","\n","for value in choice_to_hypothesis.values():\n","    value[0] = hypothesis_template.format(value[0])\n","\n","print(json.dumps(choice_to_hypothesis, indent=4))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["{\n","    \"Containment and Closure Policies\": [\n","        \"This text is related with containment and closure policy from governments in the pandemic.\"\n","    ],\n","    \"Economic Policies\": [\n","        \"This text is related with economic policy from governments in the pandemic.\"\n","    ],\n","    \"Health System Policies\": [\n","        \"This text is related with health system policy from governments in the pandemic.\"\n","    ],\n","    \"Miscellaneous Policies\": [\n","        \"This text is related with miscellaneous policy from governments in the pandemic.\"\n","    ]\n","}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6ZB-HLIwv62f"},"source":["# Prepare Data"]},{"cell_type":"code","metadata":{"id":"Y7mtfVd6MuXu","executionInfo":{"status":"ok","timestamp":1619162317819,"user_tz":420,"elapsed":86412,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["@dataclass\n","class CovidNewsData(object):\n","    id: str\n","    premise: str = None\n","    hypothesis: str = None\n","    label: str = None"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"PQctKU6h8mO_","executionInfo":{"status":"ok","timestamp":1619162317959,"user_tz":420,"elapsed":86547,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["class CovidNewsDataset(Dataset):\n","    \"\"\"\n","    Reference from https://huggingface.co/transformers/_modules/transformers/pipelines/zero_shot_classification.html#ZeroShotClassificationPipeline.__call__\n","    \"\"\"\n","    def __init__(\n","        self, \n","        data_path=None, \n","        *,\n","        tokenizer=None, \n","        choice_to_hypothesis=None,\n","        target_text='summary', \n","        max_token_len=1024, \n","        device=\"cpu\", \n","        transform=None,\n","      ):\n","        \"\"\"\n","        Args: \n","            data_path (str): The full path of the dataset. Required.\n","            target_text (str): Either use 'summary' or 'article' as inputs of the model. Default: 'summary'.\n","            tokenizer: The model's tokenizer. Required.\n","        \"\"\"\n","\n","        assert data_path is not None, f\"[self.__class__.__name__] Please specify a data path.\"\n","        assert tokenizer is not None, f\"[self.__class__.__name__] Please give a tokenizer.\"\n","        assert isinstance(choice_to_hypothesis, dict), f\"[self.__class__.__name__] Please give a dictionary for choices to hypothesis.\"\n","        assert target_text in ['summary', 'article'], f\"[self.__class__.__name__] Please pick a target_text from either 'summary' or 'article.\"\n","        self.data_path = data_path\n","        self.target_text = target_text\n","        self.tokenizer = tokenizer\n","        self.choice_to_hypothesis = choice_to_hypothesis\n","        self.class_to_id = {\n","            \"Contradiction\": 0, \n","            \"Neutral\": 1, \n","            \"Entailment\": 2, \n","        }\n","        self.max_token_len = max_token_len if max_token_len < tokenizer.model_max_length else tokenizer.model_max_length\n","        self.device = device\n","        self.transform = transform\n","\n","        # Init data\n","        self.data_list = self._get_data()\n","\n","    def __len__(self):\n","        return len(self.data_list)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.item()\n","\n","        data = self.data_list[idx]\n","        encoding = self.tokenizer(\n","            self._get_sentence_pair(data), \n","            return_tensors='pt', \n","            padding='max_length',\n","            add_special_tokens=True, \n","            truncation='only_first',  # prevent from truncating the hypothesis\n","            max_length=self.max_token_len\n","        )\n","        encoding['input_ids'] = encoding['input_ids'].squeeze()\n","        encoding['attention_mask'] = encoding['attention_mask'].squeeze()\n","\n","        sample = {\n","            'id': data.id,\n","            'inputs': self._ensure_tensor_on_device(**encoding), \n","            'label': torch.tensor(self.class_to_id[data.label], dtype=torch.long).to(device)\n","        }\n","\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","\n","        return sample\n","\n","    def _get_sentence_pair(self, data):\n","\n","        return [[data.premise, data.hypothesis]]\n","\n","    def _ensure_tensor_on_device(self, **inputs):\n","\n","        return {name: tensor.to(self.device) for name, tensor in inputs.items()}\n","\n","    def _get_data(self):\n","        with open(self.data_path) as f:\n","            raw_data_list = json.load(f)\n","\n","        labels = list(self.class_to_id.keys())\n","        data_list = []\n","        for data in raw_data_list:\n","            current_choice = data['choice']\n","            id = data['id']\n","            premise = data[self.target_text]\n","\n","            # Entailment, 3 from the current choice\n","            label = labels[2]   # Entailment\n","            for hypothesis in self.choice_to_hypothesis[current_choice]:\n","                data_list.append(CovidNewsData(\n","                    id=id,\n","                    premise=premise,\n","                    hypothesis=hypothesis,\n","                    label=label,\n","                ))\n","\n","            # Contradiction or Not Entailment, 3 from other choices seperately\n","            label = labels[0]   # Contradiction or Not Entailment\n","            for other_choice in self.choice_to_hypothesis.keys():\n","                if current_choice == other_choice: continue\n","\n","                randIdx = torch.randperm(\n","                    len(self.choice_to_hypothesis[other_choice])\n","                )[0].item()\n","                hypothesis = self.choice_to_hypothesis[other_choice][randIdx]\n","                data_list.append(CovidNewsData(\n","                    id=id,\n","                    premise=premise,\n","                    hypothesis=hypothesis,\n","                    label=label,\n","                ))\n","\n","        return data_list\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uX1IndkAcpoP","executionInfo":{"status":"ok","timestamp":1619162318602,"user_tz":420,"elapsed":87185,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["test_dataset = CovidNewsDataset(\n","    test_data_path, \n","    tokenizer=classifier.tokenizer, \n","    choice_to_hypothesis=choice_to_hypothesis,\n","    device=device\n",")\n","test_data_loader = DataLoader(\n","    dataset=test_dataset, \n","    batch_size=batch_size,\n","    shuffle=False\n",")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"olYXwUMOaZMR","executionInfo":{"status":"ok","timestamp":1619162318604,"user_tz":420,"elapsed":87181,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"f2619cbc-bcbf-4fa6-c089-11fa17ddd63a"},"source":["print(f\"Length of the testing dataset: {len(test_dataset)}\")\n","print(test_dataset[0])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Length of the testing dataset: 1744\n","{'id': 1342596, 'inputs': {'input_ids': tensor([    0, 31921, 12127,  ...,     1,     1,     1], device='cuda:0'), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')}, 'label': tensor(2, device='cuda:0')}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UPVkUa9cc7Lk"},"source":["# Prepare for Analyzing"]},{"cell_type":"code","metadata":{"id":"WWBQNfXc3gpG","executionInfo":{"status":"ok","timestamp":1619162318605,"user_tz":420,"elapsed":87168,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["criterion = nn.KLDivLoss(reduction='sum')"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_A56QEE1dzIh"},"source":["# Analyzing"]},{"cell_type":"markdown","metadata":{"id":"2CQ_aas4YRcE"},"source":["## Zero-shot (Uncomment to get the output distribution of ***bart-large-mnli*** given the dataset.)"]},{"cell_type":"code","metadata":{"id":"MhU0c9XJXW3g","executionInfo":{"status":"ok","timestamp":1619162318606,"user_tz":420,"elapsed":87164,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["# if 'classifier' not in globals() or 'classifier' not in locals():\n","#     classifier = pipeline(\n","#         'zero-shot-classification',\n","#         tokenizer='facebook/bart-large-mnli',\n","#         model='facebook/bart-large-mnli',\n","#         device=device.index,\n","#         framework='pt',\n","#     )\n","# classifier.model.eval()\n","\n","# losses = 0.\n","# zero_shot_distribution = []\n","\n","# with torch.no_grad():\n","#     for batch_idx, batch in enumerate(tqdm(test_data_loader)):\n","#         inputs = batch['inputs']\n","#         label = batch['label']\n","#         one_hot_label = F.one_hot(label, num_classes=3)\n","\n","#         outputs = classifier.model(**inputs)\n","#         output_distribution = (outputs.logits/temperature).softmax(dim=-1)\n","\n","#         loss = criterion(output_distribution.log(), one_hot_label)\n","#         losses += loss.item()\n","\n","#         zero_shot_distribution.append(output_distribution)\n","#     losses /= len(test_dataset)\n","\n","# print(' checkpoint: {} | loss (label): {:5.3f}'.format(\"facebook/bart-large-mnli\", losses))\n","\n","# torch.save(zero_shot_distribution, os.path.join(dataset_path, f\"zero_shot_distribution_temp_{temperature}.pt\"))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SWRrxp_WYZSQ"},"source":["## Few-shots & fine-tuned"]},{"cell_type":"code","metadata":{"id":"7wsd_Al93dA9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619163551218,"user_tz":420,"elapsed":16611,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"dec04f43-4e42-46ff-cbb4-d5cdb0d6a51a"},"source":["if 'zero_shot_distribution' not in locals() or 'zero_shot_distribution' not in globals():\n","    zero_shot_distribution = torch.load(os.path.join(dataset_path, f\"zero_shot_distribution_temp_{temperature}.pt\"), map_location=device)\n","\n","loss_label_record_path = os.path.join(dataset_path, f\"loss_label_record_temp_{temperature}.pt\")\n","loss_zero_shot_record_path = os.path.join(dataset_path, f\"loss_zero_shot_record_temp_{temperature}.pt\")\n","loss_label_record = torch.load(loss_label_record_path) if os.path.exists(loss_label_record_path) else {}\n","loss_zero_shot_record = torch.load(loss_zero_shot_record_path) if os.path.exists(loss_zero_shot_record_path) else {}\n","\n","for checkpoint_name in checkpoint_name_list:\n","    if 'classifier' in locals() or 'classifier' in globals():\n","        # Can't delete clearly\n","        print(\"Delete previous classifier\")\n","        classifier.model.to('cpu')\n","        del classifier\n","        torch.cuda.empty_cache()\n","\n","    # Load checkpoints\n","    model_path = os.path.join(checkpoint_path, checkpoint_name)\n","    classifier = pipeline(\n","        'zero-shot-classification',\n","        tokenizer='facebook/bart-large-mnli',\n","        model=model_path,\n","        device=device.index,\n","        framework='pt',\n","    )\n","    classifier.model.eval()\n","    print(f\"Current checkpoint: {checkpoint_name}\")\n","\n","    losses, losses_zero_shot = 0., 0.\n","    \n","    with torch.no_grad():\n","        for batch_idx, batch in enumerate(tqdm(test_data_loader)):\n","            inputs = batch['inputs']\n","            label = batch['label']\n","            one_hot_label = F.one_hot(label, num_classes=3)\n","\n","            outputs = classifier.model(**inputs)\n","            output_distribution = (outputs.logits/temperature).softmax(dim=-1)\n","\n","            loss = criterion(output_distribution.log(), one_hot_label)\n","            losses += loss.item()\n","\n","            loss = criterion(outputs.logits, zero_shot_distribution[batch_idx])\n","            losses_zero_shot += loss.item()\n","    losses /= len(test_dataset)\n","    losses_zero_shot /= len(test_dataset)\n","\n","    loss_label_record[checkpoint_name] = losses\n","    loss_zero_shot_record[checkpoint_name] = losses_zero_shot\n","\n","    print(' checkpoint: {} | loss (label): {:5.3f} | loss (zero-shot): {:5.3f}'.format(checkpoint_name, losses, losses_zero_shot))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Delete previous classifier\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/218 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current checkpoint: checkpoint_3249.bin\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 218/218 [09:21<00:00,  2.58s/it]\n"],"name":"stderr"},{"output_type":"stream","text":[" checkpoint: checkpoint_3249.bin | loss (label): 9.849 | loss (zero-shot): 2.006\n","Delete previous classifier\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/218 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current checkpoint: checkpoint_3610.bin\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 218/218 [09:37<00:00,  2.65s/it]"],"name":"stderr"},{"output_type":"stream","text":[" checkpoint: checkpoint_3610.bin | loss (label): 11.035 | loss (zero-shot): 1.856\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zP8y-TJd4DFn","executionInfo":{"status":"ok","timestamp":1619163551220,"user_tz":420,"elapsed":80,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}}},"source":["torch.save(loss_label_record, os.path.join(dataset_path, f\"loss_label_record_temp_{temperature}.pt\"))\n","torch.save(loss_zero_shot_record, os.path.join(dataset_path, f\"loss_zero_shot_record_temp_{temperature}.pt\"))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxN3q6OZrCTR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619163551222,"user_tz":420,"elapsed":72,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"cbbe54c0-2049-46c7-8aa9-5dbb54904807"},"source":["loss_label_record"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'checkpoint_1083.bin': 3.009235018305335,\n"," 'checkpoint_1444.bin': 4.105253546325695,\n"," 'checkpoint_1805.bin': 4.751828841851915,\n"," 'checkpoint_2166.bin': 6.514452876382762,\n"," 'checkpoint_2527.bin': 8.461437925422981,\n"," 'checkpoint_2888.bin': 8.945213681164542,\n"," 'checkpoint_3249.bin': 9.849357470922586,\n"," 'checkpoint_361.bin': 2.212872189939569,\n"," 'checkpoint_3610.bin': 11.03453324741014,\n"," 'checkpoint_722.bin': 1.3737209406467752}"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"vKl6nP4F-NeZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619163551223,"user_tz":420,"elapsed":64,"user":{"displayName":"Blake Chi","photoUrl":"","userId":"04508994765400846911"}},"outputId":"d2fd4061-ece5-4f7b-fb50-4df3530c3471"},"source":["loss_zero_shot_record"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'checkpoint_1083.bin': 1.7673880211120352,\n"," 'checkpoint_1444.bin': 1.9427076656747302,\n"," 'checkpoint_1805.bin': 2.0233392078395283,\n"," 'checkpoint_2166.bin': 1.8364907042422425,\n"," 'checkpoint_2527.bin': 2.0709450818393207,\n"," 'checkpoint_2888.bin': 1.8245160898210806,\n"," 'checkpoint_3249.bin': 2.006164341276392,\n"," 'checkpoint_361.bin': 1.4395465304682014,\n"," 'checkpoint_3610.bin': 1.8559674210162884,\n"," 'checkpoint_722.bin': 1.6387985161411653}"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"i8OPAOe-tkpE"},"source":[""],"execution_count":null,"outputs":[]}]}